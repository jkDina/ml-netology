{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2.1. Деревья решений. Классификация"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Agenda:\n",
    "* критерий информативности с нуля\n",
    "* визуализация разделяющих поверхностей решения и визуализация самого дерева\n",
    "* оценка важности фичей\n",
    "* ужасы переобучения"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Критерий информативности с нуля"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "как мы разобрали, построение дерева зависит от следующих факторов:\n",
    "* вид правила разбиения\n",
    "* критерий информативности\n",
    "* критерий останова\n",
    "* метод стрижки\n",
    "* проблема пропусков\n",
    "\n",
    "пройдёмся критериям информативности"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Нам понадобятся две библиотеки: numpy вы знаете, а объект класса Counter в заданном списке просто подсчитывает количество вхождений каждого элемента и возвращает результат в виде словаря. Пример:*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Counter([9,9,9,7,7])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Для численного измерения улучшения разбиений на каждом этапе мы вводим некоторый *критерий информативности*, который будет оценивать разнообразие объектов в выборке: чем больше разных классов в выборке, тем больше значение H(R). Чем меньше взвешенное значение критерия после разбиения - тем лучше*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ниже представлена функция для расчёта энтропийного критерия качества:\n",
    "\n",
    "$H(R) = -\\sum_{k=1}^{K}p_klogp_k$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Задание.** Дополните функцию расчёта энтропийного критерия множества"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def HEntropy(l):\n",
    "    length = len(l)\n",
    "    cnt = Counter(l)\n",
    "    \n",
    "    pass #your code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Задание.** По аналогии с *энтропийным критерием* заполните функции *критерия Джини*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def HGini(l):\n",
    "    #your code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Information Gain (IG)* - функционал качества, отвечающий на вопрос, а сколько энтропии мы погасили при определённом разбиении? На каждом шаге разбиения при построении дерева максимизируется IG. Формула для вычисления при критерии информативности H:\n",
    "\n",
    "$IG(R) = H(R) - \\frac{|R_l|}{|R|}H(R_l) - \\frac{|R_r|}{|R|}H(R_r)$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Задание.** Заполните функцию для вычисления функционала качества"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def IG(H, l, i):\n",
    "    pass #your code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Здесь я подготовил функцию для визуализации работы произвольного критерия качества на выборке"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def test_H(H, l):\n",
    "    print(\"{:5} {:3}   {:4} {:4} {:4}\".format(\"#\",\"l\",\"IG\",\"Hl\",\"Hr\"))\n",
    "    print(\"-\"*24)\n",
    "    for i in range(1,len(l)):\n",
    "        print(\"{:2}. {:3}   {:.2f} {:.2f} {:.2f}\".format(i, l[i], IG(H, l, i), H(l[:i]), H(l[i:])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ну что, определим как-нибудь выборку и посмотрим, какое разбиение предложат критерии информативности. Замечу, что элементы здесь будут выводиться начиная со второго, а значения функций рассчитаны для разбиения *перед* элементом строки"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "l = [1]*5 + [2]*3 + [1]*4\n",
    "print(l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "test_H(HEntropy, l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "test_H(HGini, l)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Задание.** проверьте, какое разбиение будет сделано на втором шаге?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pass #your code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Визуализация принятия решений классификатором sklearn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. Используем данные о цветках ириса из занятия"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "%matplotlib inline\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "iris = load_iris()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X = pd.DataFrame(iris.data, columns=iris.feature_names)\n",
    "y = pd.DataFrame(iris.target, columns=['species'])\n",
    "df = pd.concat([X,y], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print(df.shape)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Выведем попарное распределение фичей датасета с раскраской по виду цветка"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sns.pairplot(df, hue='species', diag_kind=\"kde\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "визуально кажется, что ширина листка (petal width) даже самостоятельно может отделить два класса друг от друга идеально, а ещё для двух понадобится хотя бы ещё одна фича.\n",
    "\n",
    "Возьмём пока для возможности изобразить это в 2D две фичи: длину и ширину листка"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Xcut = X[X.columns[2:4]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. Используем классификатор"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "DecisionTreeClassifier?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "clf = DecisionTreeClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "clf.fit(Xcut, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "clf.predict([ [1,1], [3,3] ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "clf.predict_proba([ [1,1], [3,3] ])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Супер, можем теперь предсказывать. Давайте визуализируем границу принятия решений. Для удобства экспереминтирования я упаковал всё в функцию **test_clf**, в неё передаётся созданный классификатор и при установленном fit_clf=True обучается внутри, а затем отрисовывает границу. Таким образом можно экспериментировать с параметрами классификатора"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_grid(data):\n",
    "    x_min, x_max = data[:, 0].min() - 1, data[:, 0].max() + 1\n",
    "    y_min, y_max = data[:, 1].min() - 1, data[:, 1].max() + 1\n",
    "    return np.meshgrid(np.arange(x_min, x_max, 0.01), np.arange(y_min, y_max, 0.01))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def test_clf(clf, X, y, cmap=None, fit_clf=False):\n",
    "    xx,yy = get_grid(X.values)\n",
    "    if fit_clf:\n",
    "        clf.fit(X, y)\n",
    "    predicted = clf.predict(np.c_[xx.ravel(), yy.ravel()]).reshape(xx.shape)\n",
    "    plt.figure(figsize=(8, 8))\n",
    "    plt.pcolormesh(xx, yy, predicted, cmap=cmap or 'spring')\n",
    "    plt.scatter(X.values[:, 0], X.values[:, 1], c=y, s=100, cmap=cmap or 'spring')\n",
    "    if fit_clf:\n",
    "        return clf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*попробуйте при разной глубине*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "clf = test_clf(DecisionTreeClassifier(), Xcut, y, fit_clf=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "обратите внимание, один блок занимает то позицию снизу, то слева: данных недостаточно для принятия однозначного решения и экстраполяция идёт произвольно"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3. Визуализируем само дерево"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Возможно, самое замечательное свойство одиночных деревьев - возможность визуализировать их алгоритм работы и затем объяснить его хоть человеку, хоть машине\n",
    "\n",
    "Дерево можно как-то отобразить внутри ipython-ноутбука с помощью библиотеки pydot и установлнного webgraphviz, но мы воспользуемся скорее онлайн-сервисом http://www.webgraphviz.com\n",
    "\n",
    "Сгенерируем код дерева в формате .dot и скопируем его на сайт"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.tree import export_graphviz\n",
    "\n",
    "def get_tree_dot_view(clf, feature_names=None, class_names=None):\n",
    "    print(export_graphviz(clf, out_file=None, filled=True, feature_names=feature_names, class_names=class_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "clf = DecisionTreeClassifier(max_depth=3)\n",
    "clf.fit(Xcut, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "get_tree_dot_view(clf, list(Xcut.columns), iris.target_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Задание**\n",
    "1. визуализировать дерево\n",
    "2. вставить скрин с картинкой сюда в ipython notebook (!\\[text](imagename.png))\n",
    "3. проверить индексы Джини в узлах: совпадают с нашей расчётной функцией?\n",
    "4. ветка налево - это True или False? что значит цвет узла? class? values?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Оценка важности фичей"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "важность зависит от конкретного прогона классификатора, это не объективный показатель, но дающий представление"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*попробуйте при разной глубине*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "clf = DecisionTreeClassifier(max_depth=3)\n",
    "clf.fit(X, y)\n",
    "\n",
    "plt.barh(np.arange(len(clf.feature_importances_)), clf.feature_importances_)\n",
    "plt.yticks(np.arange(len(X.columns)),X.columns)\n",
    "''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Переообучение наглядно"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*здесь я использую генерацию датасета из [блога](https://habrahabr.ru/company/ods/blog/322534/) open data science*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "np.seed = 7\n",
    "train_data = np.random.normal(size=(100, 2))\n",
    "train_labels = np.zeros(100)\n",
    "train_data = np.r_[train_data, np.random.normal(size=(100, 2), loc=2)]\n",
    "train_labels = np.r_[train_labels, np.ones(100)]\n",
    "train_data = pd.DataFrame(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "plt.scatter(train_data[0], train_data[1], c=train_labels, s=100, cmap='autumn', edgecolors='black', linewidth=1.5);\n",
    "plt.plot(range(-2,5), range(4,-3,-1));"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*попробуйте при разной глубине*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "clf = test_clf(DecisionTreeClassifier(max_depth=1), train_data, train_labels, cmap='autumn', fit_clf=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "clf = test_clf(DecisionTreeClassifier(), train_data, train_labels, cmap='autumn', fit_clf=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "А здесь можно увидеть огромное переобученное дерево: http://www.webgraphviz.com"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "get_tree_dot_view(DecisionTreeClassifier(max_depth=10), feature_names=['x','y'])"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
